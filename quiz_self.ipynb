{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d081506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import root_mean_squared_error as RMSE\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bc3038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  user_id  item_id    rating\n",
      "0              0        9       55  1.807853\n",
      "1              1      142       54  1.450524\n",
      "2              2      126       23  0.972784\n",
      "3              3        1       12  1.413113\n",
      "4              4      164       57  1.467390\n",
      "...          ...      ...      ...       ...\n",
      "3512        3512      187       28  1.034759\n",
      "3513        3513       92       93  2.022145\n",
      "3514        3514      152       69  1.688438\n",
      "3515        3515      138       70  1.666404\n",
      "3516        3516       35       86  2.132165\n",
      "\n",
      "[3517 rows x 4 columns]\n",
      "     Unnamed: 0  user_id  item_id\n",
      "0             0      101       54\n",
      "1             1       18       81\n",
      "2             2       28       16\n",
      "3             3      152       63\n",
      "4             4       22       15\n",
      "..          ...      ...      ...\n",
      "875         875       62       62\n",
      "876         876        7       16\n",
      "877         877      189       32\n",
      "878         878      130       59\n",
      "879         879      108       80\n",
      "\n",
      "[880 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset from kaggle compeition: CUHK_STAT3009_2025\n",
    "import pandas as pd\n",
    "test_data = pd.read_csv('/Users/lamhoichun/Desktop/STAT3009/Lecture/test.csv')\n",
    "train_data = pd.read_csv('/Users/lamhoichun/Desktop/STAT3009/Lecture/train.csv') \n",
    "\n",
    "# Check the first few rows of the train_data\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c951fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.values\n",
    "train_data = train_data.values\n",
    "X_train = train_data[:,1:3]\n",
    "y_train = train_data[:,3]\n",
    "X_test = test_data[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51f8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Estimator Class: User Average RS\n",
    "class UserAvg (BaseEstimator):\n",
    "    def __init__(self, n_user, min_data=0):\n",
    "        # Setup parameters\n",
    "        self.n_user = n_user\n",
    "        # Fitting parameters\n",
    "        self.global_avg = 0\n",
    "        self.user_avg = np.zeros(n_user)\n",
    "        # Hyper-parameters\n",
    "        self.min_data = 3\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Find the global average\n",
    "        self.global_avg = np.mean(y)\n",
    "\n",
    "        # Find the user average\n",
    "        for user_temp in range(self.n_user):\n",
    "            # Find the index of the user\n",
    "            # user_index: the records of that user\n",
    "            user_index = np.where(X[:,0] == user_temp)[0]\n",
    "            if len(user_index) <= self.min_data:\n",
    "                # Use global average when a user has less than min_data records\n",
    "                self.user_avg[user_temp] = self.global_avg\n",
    "            else:\n",
    "                # Compute the user average of existing users\n",
    "                self.user_avg[user_temp] = np.mean(y[user_index])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Get the user_index\n",
    "        user_index = X[:,0]-1\n",
    "        return self.user_avg[user_index]\n",
    "\n",
    "        # Make predictions\n",
    "        # y = np.ones(len(X))\n",
    "        # return y * self.user_avg[X[:,0]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc46b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 198\n"
     ]
    }
   ],
   "source": [
    "n_user = len(set(set(X_train[:,0]).union(set(X_test[:,0]))))\n",
    "print(f\"Number of users: {n_user}\")\n",
    "\n",
    "myuser = UserAvg(n_user=n_user)\n",
    "myuser.fit(X_train, y_train)\n",
    "y_pred = myuser.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "836ab2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store y_pred in submission.csv with column Id and rating\n",
    "submission = pd.DataFrame({'Id': test_data[:,0], 'rating': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff2931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'min_data': 0}\n",
      "Best estimator: UserAvg(n_user=198)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamhoichun/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lamhoichun/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/Users/lamhoichun/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/lamhoichun/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "  File \"/Users/lamhoichun/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/lamhoichun/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "  File \"/var/folders/6n/9c4tnn9s11jd3vyn0hknk12h0000gn/T/ipykernel_15361/639119671.py\", line 32, in predict\n",
      "    return self.user_avg[user_index]\n",
      "IndexError: arrays used as indices must be of integer (or boolean) type\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/lamhoichun/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "hp_grid = {'min_data': [0, 3, 5, 10]}\n",
    "\n",
    "myuser = UserAvg(n_user=n_user)\n",
    "gs_user = GridSearchCV(estimator = myuser, \n",
    "                        param_grid = hp_grid, \n",
    "                        cv = 3, \n",
    "                        scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "# Fit the model and make predictions\n",
    "gs_user.fit(X_train, y_train)\n",
    "y_pred = gs_user.predict(X_test)\n",
    "\n",
    "# Print the best hyper-parameters\n",
    "print(f\"Best parameters: {gs_user.best_params_}\")\n",
    "# Print the best estimator\n",
    "print(f\"Best estimator: {gs_user.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "210b0067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 98\n"
     ]
    }
   ],
   "source": [
    "# Compute the n_item correctly - considering all unique items from both train and test\n",
    "n_item = len(set(list(X_train[:,1]) + list(X_test[:,1])))\n",
    "print(f\"Number of items: {n_item}\")\n",
    "\n",
    "# Base Estimator Class: Item Average RS  \n",
    "class ItemAvg (BaseEstimator):\n",
    "    def __init__(self, min_data=0):\n",
    "        # We'll determine n_item dynamically\n",
    "        self.min_data = min_data\n",
    "        self.global_avg = 0\n",
    "        self.item_avg = None\n",
    "        self.item_to_idx = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Find the global average\n",
    "        self.global_avg = np.mean(y)\n",
    "\n",
    "        # Get unique items and create mapping\n",
    "        unique_items = sorted(set(X[:,1]))\n",
    "        self.item_to_idx = {item_id: idx for idx, item_id in enumerate(unique_items)}\n",
    "        \n",
    "        # Initialize item averages array\n",
    "        self.item_avg = np.zeros(len(unique_items))\n",
    "\n",
    "        # Compute averages for each item\n",
    "        for i, item_id in enumerate(unique_items):\n",
    "            item_records = np.where(X[:,1] == item_id)[0]\n",
    "            if len(item_records) <= self.min_data:\n",
    "                self.item_avg[i] = self.global_avg\n",
    "            else:\n",
    "                self.item_avg[i] = np.mean(y[item_records])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        item_ids = X[:,1]\n",
    "        predictions = []\n",
    "        for item_id in item_ids:\n",
    "            if item_id in self.item_to_idx:\n",
    "                predictions.append(self.item_avg[self.item_to_idx[item_id]])\n",
    "            else:\n",
    "                # Use global average for completely unseen items\n",
    "                predictions.append(self.global_avg)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93848f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the ratings using item average model\n",
    "myitem = ItemAvg(min_data=0)  # Remove n_item parameter since we'll compute it dynamically\n",
    "myitem.fit(X_train, y_train)\n",
    "y_pred = myitem.predict(X_test)\n",
    "\n",
    "# Store y_pred in submission.csv with column Id and rating\n",
    "submission = pd.DataFrame({'Id': test_data[:,0], 'rating': y_pred})  # Use test_data[:,0] for Id column\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1811fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Estimator Class: Item Average RS with dual thresholds\n",
    "class ItemAvg (BaseEstimator):\n",
    "    def __init__(self, min_data=0, min_item=0):\n",
    "        # Hyper-parameters\n",
    "        self.min_data = min_data\n",
    "        self.min_item = min_item\n",
    "        # Fitting parameters (will be set during fit)\n",
    "        self.global_avg = 0\n",
    "        self.item_avg = None\n",
    "        self.item_to_idx = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Find the global average\n",
    "        self.global_avg = np.mean(y)\n",
    "\n",
    "        # Get unique items\n",
    "        unique_items = sorted(set(X[:,1]))\n",
    "        self.item_to_idx = {item_id: idx for idx, item_id in enumerate(unique_items)}\n",
    "        \n",
    "        # Initialize item averages array\n",
    "        self.item_avg = np.zeros(len(unique_items))\n",
    "\n",
    "        # Compute averages for each item\n",
    "        for i, item_id in enumerate(unique_items):\n",
    "            item_records = np.where(X[:,1] == item_id)[0]\n",
    "            \n",
    "            if len(item_records) <= self.min_data:\n",
    "                # Use global average when an item has less than min_data records\n",
    "                self.item_avg[i] = self.global_avg\n",
    "            elif len(item_records) < self.min_item:\n",
    "                # Use global average when item doesn't meet min_item threshold\n",
    "                self.item_avg[i] = self.global_avg\n",
    "            else:\n",
    "                # Compute the item average\n",
    "                self.item_avg[i] = np.mean(y[item_records])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        item_ids = X[:,1]\n",
    "        predictions = []\n",
    "        \n",
    "        for item_id in item_ids:\n",
    "            if item_id in self.item_to_idx:\n",
    "                predictions.append(self.item_avg[self.item_to_idx[item_id]])\n",
    "            else:\n",
    "                predictions.append(self.global_avg)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872cfef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with corrected ItemAvg class\n",
    "hp_grid = {'min_data': [0,1,2,3,10,100]}\n",
    "\n",
    "myitem = ItemAvg()\n",
    "gs_item = GridSearchCV(estimator=myitem, \n",
    "                        param_grid=hp_grid, \n",
    "                        cv=5, \n",
    "                        scoring='neg_root_mean_squared_error')\n",
    "gs_item.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gs_item.predict(X_test)\n",
    "submission = pd.DataFrame({'Id': test_data[:,0], 'rating': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f6810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and make predictions\n",
    "gs_item.fit(X_train, y_train)\n",
    "y_pred = gs_item.predict(X_test)\n",
    "\n",
    "# Save y_pred in submission.csv with column Id and rating\n",
    "submission = pd.DataFrame({'Id': test_data[:,0], 'rating': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84efd76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_data': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_item.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
